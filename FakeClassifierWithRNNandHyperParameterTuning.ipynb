{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### skip warning if any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import all required lib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title           author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...    Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  Daniel J. Flynn   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title            author  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...  David Streitfeld   \n",
       "1  20801  Russian warships ready to strike terrorists ne...               NaN   \n",
       "\n",
       "                                                text  \n",
       "0  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1  Russian warships ready to strike terrorists ne...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    558\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can find that only fake news are having text as null, so we can drop respective data with other column containing null values \n",
    "df_train[df_train.isnull()['title']==True]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "title     0\n",
       "author    0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2248f8ddd88>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### we will try to visualize some distribution, so using countplot data is not imbalanced\n",
    "sns.countplot(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import NLP specific data pre-processing libraries\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function for cleaning text like remove punctuations, digits and other than alphabet word\n",
    "def text_analyzer(messages):\n",
    "    porter = PorterStemmer()\n",
    "    clean_corpus = []\n",
    "    \n",
    "    for i in range(len(messages)):\n",
    "        \n",
    "        text = messages.iloc[i]\n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',text)\n",
    "        \n",
    "        clean_text = clean_text.lower()\n",
    "        clean_text = clean_text.split()\n",
    "        \n",
    "        clean_text = [porter.stem(word) for word in clean_text if word not in stopwords.words('english')]\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        \n",
    "        clean_corpus.append(clean_text)\n",
    "        \n",
    "    return clean_corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18285\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_messages = text_analyzer(df_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri',\n",
       " 'jacki mason hollywood would love trump bomb north korea lack tran bathroom exclus video breitbart',\n",
       " 'beno hamon win french socialist parti presidenti nomin new york time',\n",
       " 'back channel plan ukrain russia courtesi trump associ new york time',\n",
       " 'obama organ action partner soro link indivis disrupt trump agenda',\n",
       " 'bbc comedi sketch real housew isi caus outrag']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_messages[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we will work on Word embedding now\n",
    "#### declare variable vocabulary size\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence lenght in training corpus is 47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for msg in train_clean_messages:\n",
    "    msg_len = len(msg.split())\n",
    "    if msg_len > max_len:\n",
    "        max_len=msg_len\n",
    "\n",
    "print('Max Sentence lenght in training corpus is',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we will set sentence lenght to 30 as in testing corpus max sentence lenght is 27\n",
    "sent_len=25\n",
    "# we will set dimention as 40\n",
    "dim=40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### we will import some packages which are required for one hot representation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_corpus(vocsize,sentlen,message):\n",
    "    try:\n",
    "        one_hot_corpus = [one_hot(word,vocsize) for word in message]\n",
    "        padded_corpus = pad_sequences(one_hot_corpus,padding='pre',maxlen=sentlen)\n",
    "    except e:\n",
    "        print('exception is',e)\n",
    "    finally:\n",
    "        return padded_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_word_corpus=get_embedded_corpus(voc_size,sent_len,train_clean_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18285"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_word_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 1356, 4498, 2444, 1543,  601, 3844, 4369,\n",
       "        3661, 2146,  557],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0, 3137, 1388, 2314, 2319,\n",
       "        2240,  340, 2352]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_word_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now we will create neural network for text classification\n",
    "#### import required lib for the same\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models for hyper parameter tuning\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for i,nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Embedding(voc_size,dim,input_length=sent_len))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(nodes))       \n",
    "            model.add(Dropout(0.2))\n",
    "        elif i==1:\n",
    "            model.add(LSTM(nodes))       \n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(Dense(nodes,activation='relu'))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded corpus (18285, 25)\n",
      "Type of embedded corpus <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Shape of embedded corpus',cleaned_word_corpus.shape)\n",
    "print('Type of embedded corpus',type(cleaned_word_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cleaned_word_corpus\n",
    "y=df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label (18285,)\n",
      "Type of label <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print('Shape of label',y.shape)\n",
    "print('Type of label',type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1]\n",
      "Type of label <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "print(y[:5])\n",
    "print('Type of label',type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we will now train and fit the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\slage\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\slage\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 9s 601us/step - loss: 0.4132 - accuracy: 0.8015\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 7s 503us/step - loss: 0.1648 - accuracy: 0.9350\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 9s 587us/step - loss: 0.1219 - accuracy: 0.9547\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 9s 587us/step - loss: 0.0960 - accuracy: 0.9649\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 8s 568us/step - loss: 0.0763 - accuracy: 0.9726\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 7s 504us/step - loss: 0.0638 - accuracy: 0.9796\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 8s 547us/step - loss: 0.0468 - accuracy: 0.9850\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 9s 636us/step - loss: 0.0369 - accuracy: 0.98790s - loss: 0.037\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 9s 614us/step - loss: 0.0300 - accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 7s 506us/step - loss: 0.0233 - accuracy: 0.9926\n",
      "3657/3657 [==============================] - 1s 254us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 10s 664us/step - loss: 0.4160 - accuracy: 0.7999\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 9s 629us/step - loss: 0.1642 - accuracy: 0.9329\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 9s 627us/step - loss: 0.1208 - accuracy: 0.9517\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 9s 623us/step - loss: 0.0945 - accuracy: 0.9651\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 9s 623us/step - loss: 0.0753 - accuracy: 0.9724\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 9s 626us/step - loss: 0.0607 - accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 9s 625us/step - loss: 0.0425 - accuracy: 0.9860\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 9s 598us/step - loss: 0.0333 - accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 9s 606us/step - loss: 0.0242 - accuracy: 0.9920\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 8s 577us/step - loss: 0.0173 - accuracy: 0.9946\n",
      "3657/3657 [==============================] - 1s 224us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 10s 664us/step - loss: 0.4091 - accuracy: 0.7991\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 9s 620us/step - loss: 0.1624 - accuracy: 0.9350\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 9s 616us/step - loss: 0.1175 - accuracy: 0.9555\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 9s 626us/step - loss: 0.0924 - accuracy: 0.9655\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 9s 636us/step - loss: 0.0707 - accuracy: 0.9755\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 10s 658us/step - loss: 0.0567 - accuracy: 0.9817\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 9s 634us/step - loss: 0.0402 - accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 10s 650us/step - loss: 0.0309 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 9s 640us/step - loss: 0.0251 - accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 8s 568us/step - loss: 0.0186 - accuracy: 0.9947\n",
      "3657/3657 [==============================] - 1s 218us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 6s 418us/step - loss: 0.4161 - accuracy: 0.7960\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 7s 493us/step - loss: 0.1612 - accuracy: 0.9367\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 6s 407us/step - loss: 0.1248 - accuracy: 0.9524\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 8s 539us/step - loss: 0.1040 - accuracy: 0.9615\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 6s 443us/step - loss: 0.0816 - accuracy: 0.9705\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 9s 593us/step - loss: 0.0637 - accuracy: 0.9782\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 10s 675us/step - loss: 0.0507 - accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 10s 661us/step - loss: 0.0393 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 10s 681us/step - loss: 0.0291 - accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 10s 687us/step - loss: 0.0238 - accuracy: 0.9927\n",
      "3657/3657 [==============================] - 1s 266us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 11s 774us/step - loss: 0.4018 - accuracy: 0.8067\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 11s 731us/step - loss: 0.1632 - accuracy: 0.9361\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 11s 733us/step - loss: 0.1203 - accuracy: 0.9564\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 11s 722us/step - loss: 0.0973 - accuracy: 0.9637\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 10s 705us/step - loss: 0.0792 - accuracy: 0.9718\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 10s 705us/step - loss: 0.0667 - accuracy: 0.9776\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 10s 692us/step - loss: 0.0545 - accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 10s 662us/step - loss: 0.0419 - accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 10s 684us/step - loss: 0.0352 - accuracy: 0.9876\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 10s 670us/step - loss: 0.0300 - accuracy: 0.9900\n",
      "3657/3657 [==============================] - 1s 266us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 10s 667us/step - loss: 0.5278 - accuracy: 0.7309\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 8s 573us/step - loss: 0.2204 - accuracy: 0.9104\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 8s 563us/step - loss: 0.1441 - accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 8s 558us/step - loss: 0.1092 - accuracy: 0.9608\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 8s 569us/step - loss: 0.0843 - accuracy: 0.9708\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 8s 573us/step - loss: 0.0672 - accuracy: 0.9769\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 9s 592us/step - loss: 0.0493 - accuracy: 0.9846\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 9s 626us/step - loss: 0.0394 - accuracy: 0.9882\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 9s 620us/step - loss: 0.0351 - accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 9s 611us/step - loss: 0.0243 - accuracy: 0.9930\n",
      "3657/3657 [==============================] - 1s 262us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 10s 716us/step - loss: 0.5272 - accuracy: 0.7353\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 10s 661us/step - loss: 0.2318 - accuracy: 0.9041\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 10s 663us/step - loss: 0.1513 - accuracy: 0.9407\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 9s 635us/step - loss: 0.1172 - accuracy: 0.9562\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 9s 606us/step - loss: 0.1015 - accuracy: 0.9629\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 9s 625us/step - loss: 0.0813 - accuracy: 0.9719\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 9s 632us/step - loss: 0.0731 - accuracy: 0.9737\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 7s 469us/step - loss: 0.0587 - accuracy: 0.9802\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14628/14628 [==============================] - 9s 595us/step - loss: 0.0562 - accuracy: 0.9804\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 9s 630us/step - loss: 0.0422 - accuracy: 0.9859\n",
      "3657/3657 [==============================] - 1s 277us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 11s 769us/step - loss: 0.5407 - accuracy: 0.7200\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 10s 683us/step - loss: 0.2183 - accuracy: 0.9114\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 10s 657us/step - loss: 0.1417 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 8s 541us/step - loss: 0.1089 - accuracy: 0.9599\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 10s 666us/step - loss: 0.0859 - accuracy: 0.9709\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 10s 682us/step - loss: 0.0723 - accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 10s 671us/step - loss: 0.0525 - accuracy: 0.9829\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 9s 626us/step - loss: 0.0414 - accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 9s 630us/step - loss: 0.0287 - accuracy: 0.9915\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 10s 665us/step - loss: 0.0217 - accuracy: 0.9937\n",
      "3657/3657 [==============================] - 1s 259us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 11s 761us/step - loss: 0.5494 - accuracy: 0.7178\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 10s 659us/step - loss: 0.2324 - accuracy: 0.9061\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 10s 665us/step - loss: 0.1485 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 9s 645us/step - loss: 0.1164 - accuracy: 0.9549\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 9s 649us/step - loss: 0.0941 - accuracy: 0.9645\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 10s 655us/step - loss: 0.0839 - accuracy: 0.9699\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 10s 655us/step - loss: 0.0682 - accuracy: 0.9770\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 10s 661us/step - loss: 0.0566 - accuracy: 0.9815\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 10s 670us/step - loss: 0.0446 - accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 10s 672us/step - loss: 0.0348 - accuracy: 0.9888\n",
      "3657/3657 [==============================] - 1s 367us/step\n",
      "Epoch 1/10\n",
      "14628/14628 [==============================] - 12s 831us/step - loss: 0.5426 - accuracy: 0.7283\n",
      "Epoch 2/10\n",
      "14628/14628 [==============================] - 11s 760us/step - loss: 0.2313 - accuracy: 0.9059\n",
      "Epoch 3/10\n",
      "14628/14628 [==============================] - 11s 748us/step - loss: 0.1476 - accuracy: 0.9444\n",
      "Epoch 4/10\n",
      "14628/14628 [==============================] - 11s 737us/step - loss: 0.1142 - accuracy: 0.9573\n",
      "Epoch 5/10\n",
      "14628/14628 [==============================] - 10s 704us/step - loss: 0.0929 - accuracy: 0.9668\n",
      "Epoch 6/10\n",
      "14628/14628 [==============================] - 10s 677us/step - loss: 0.0816 - accuracy: 0.9711\n",
      "Epoch 7/10\n",
      "14628/14628 [==============================] - 9s 648us/step - loss: 0.0677 - accuracy: 0.9777\n",
      "Epoch 8/10\n",
      "14628/14628 [==============================] - 10s 662us/step - loss: 0.0553 - accuracy: 0.9802\n",
      "Epoch 9/10\n",
      "14628/14628 [==============================] - 10s 687us/step - loss: 0.0539 - accuracy: 0.9823\n",
      "Epoch 10/10\n",
      "14628/14628 [==============================] - 10s 689us/step - loss: 0.0452 - accuracy: 0.9858\n",
      "3657/3657 [==============================] - 1s 216us/step\n",
      "Epoch 1/10\n",
      "18285/18285 [==============================] - 14s 765us/step - loss: 0.4873 - accuracy: 0.7562\n",
      "Epoch 2/10\n",
      "18285/18285 [==============================] - 14s 776us/step - loss: 0.1882 - accuracy: 0.9270\n",
      "Epoch 3/10\n",
      "18285/18285 [==============================] - 14s 781us/step - loss: 0.1353 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "18285/18285 [==============================] - 14s 785us/step - loss: 0.1158 - accuracy: 0.9579\n",
      "Epoch 5/10\n",
      "18285/18285 [==============================] - 14s 784us/step - loss: 0.0986 - accuracy: 0.9635\n",
      "Epoch 6/10\n",
      "18285/18285 [==============================] - 13s 737us/step - loss: 0.0892 - accuracy: 0.9681\n",
      "Epoch 7/10\n",
      "18285/18285 [==============================] - 14s 779us/step - loss: 0.0803 - accuracy: 0.9717\n",
      "Epoch 8/10\n",
      "18285/18285 [==============================] - 13s 703us/step - loss: 0.0689 - accuracy: 0.9749\n",
      "Epoch 9/10\n",
      "18285/18285 [==============================] - 15s 801us/step - loss: 0.0606 - accuracy: 0.9803s - loss: 0.0599 - accuracy: 0.\n",
      "Epoch 10/10\n",
      "18285/18285 [==============================] - 12s 679us/step - loss: 0.0585 - accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "layers = [(100,),(50,50),(50,100,100,50)]\n",
    "\n",
    "param_grid = dict(layers=layers,batch_size=[128,256],epochs=[10])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
    "\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### we will check classification report and confusion matrix for calculating accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = grid_result.best_params_\n",
    "\n",
    "# predict output\n",
    "y_pred = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3372   47]\n",
      " [  23 2593]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3419\n",
      "           1       0.98      0.99      0.99      2616\n",
      "\n",
      "    accuracy                           0.99      6035\n",
      "   macro avg       0.99      0.99      0.99      6035\n",
      "weighted avg       0.99      0.99      0.99      6035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 256, 'epochs': 10, 'layers': (100,)}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  20800      0\n",
       "1  20801      1\n",
       "2  20802      0\n",
       "3  20803      1\n",
       "4  20804      1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### now we will try to fit this model on test data\n",
    "submission = pd.read_csv('submit.csv')\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of submission df 5200\n",
      "length of test df (null already removed) 4575\n"
     ]
    }
   ],
   "source": [
    "print('length of submission df',len(submission))\n",
    "print('length of test df (null already removed)',len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(df_test,submission,how='inner')[['title','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pelosi Calls for FBI Investigation to Find Out...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  Specter of Trump Loosens Tongues, if Not Purse...      0\n",
       "1  #NoDAPL: Native American Leaders Vow to Stay A...      0\n",
       "2  Tim Tebow Will Attempt Another Comeback, This ...      1\n",
       "3                    Keiser Report: Meme Wars (E995)      1\n",
       "4  Pelosi Calls for FBI Investigation to Find Out...      1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x224ce0ea308>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_messages = text_analyzer(test_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence lenght in corpus is testing data 29\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for msg in test_clean_messages:\n",
    "    msg_len = len(msg.split())\n",
    "    if msg_len > max_len:\n",
    "        max_len=msg_len\n",
    "\n",
    "print('Max Sentence lenght in corpus is testing data',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can set sentence lenght as set in training\n",
    "cleaned_test_word_corpus=get_embedded_corpus(voc_size,sent_len,test_clean_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0, 2359,  178, 4010, 2580, 1337,  225, 1986, 3418,\n",
       "        3200, 4339, 4413],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,  976,  419, 2216, 4554, 4799, 2409, 2700,\n",
       "        4843, 2773, 4235],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0, 3060, 4778, 1876, 3315, 1918, 4413, 1083,\n",
       "        3200, 4339, 4413],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0, 4700,  215,\n",
       "         466, 2651, 1538],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,  608, 3660, 2222,    7,   23, 1663,\n",
       "        3590,  178, 2352]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_word_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = grid_result.predict(cleaned_test_word_corpus)\n",
    "#y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4575"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_y=list(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = [int(i) for i in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1, 1]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.70      0.64      2213\n",
      "           1       0.66      0.56      0.61      2362\n",
      "\n",
      "    accuracy                           0.63      4575\n",
      "   macro avg       0.63      0.63      0.62      4575\n",
      "weighted avg       0.63      0.63      0.62      4575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_test_y,y_pred_test))\n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1546  667]\n",
      " [1045 1317]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(real_test_y,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will dump model now\n",
    "import pickle\n",
    "file_ip=open('ModelFakeClassifier.pkl','wb')\n",
    "pickle.dump(grid_result,file_ip)\n",
    "\n",
    "file_ip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
