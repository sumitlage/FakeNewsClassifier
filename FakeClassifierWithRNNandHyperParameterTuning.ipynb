{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### skip warning if any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import all required lib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title           author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...    Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...  Daniel J. Flynn   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title            author  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...  David Streitfeld   \n",
       "1  20801  Russian warships ready to strike terrorists ne...               NaN   \n",
       "\n",
       "                                                text  \n",
       "0  PALO ALTO, Calif.  —   After years of scorning...  \n",
       "1  Russian warships ready to strike terrorists ne...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title      558\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    558\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can find that only fake news are having text as null, so we can drop respective data with other column containing null values \n",
    "df_train[df_train.isnull()['title']==True]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['title'].fillna('Fake Fake Fake',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id           0\n",
       "title        0\n",
       "author    1957\n",
       "text        39\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[df_train['title']=='Fake Fake Fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title     122\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['title'].fillna('Fake Fake Fake',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "title       0\n",
       "author    503\n",
       "text        7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[df_test['title']=='Fake Fake Fake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1aeee743388>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQl0lEQVR4nO3df6zddX3H8edLCuKPIUWuDFtmcTY6dBqhAdTETFmgsM0yAwajo2FNumxsumW/cH+sC8iimY6pU5JGKsUZkaAbbHOSBn/FTZFbYfyUtEFH70C4rhV/xR/V9/44n6tHuC2XT7nn9Hqej+TkfL/v7+f7Pe9vc9NXvj/O96SqkCSpx5PG3YAkaekyRCRJ3QwRSVI3Q0SS1M0QkSR1WzbuBkbt6KOPrlWrVo27DUlaMrZv3/71qpqab9nEhciqVauYnp4edxuStGQk+Z99LfN0liSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKnbxH1j/UCd9OdXjbsFHYS2/935424BgPsu/tVxt6CD0C/99e2Ltm2PRCRJ3QwRSVI3Q0SS1M0QkSR1W7QQSbIlyUNJ7hiqHZVkW5Id7X15qyfJu5PsTHJbkhOH1lnfxu9Isn6oflKS29s6706SxdoXSdL8FvNI5Epg7SNqFwE3VtVq4MY2D3AmsLq9NgKXwyB0gE3AKcDJwKa54GljNg6t98jPkiQtskULkar6LLD7EeV1wNY2vRU4e6h+VQ18ATgyybHAGcC2qtpdVXuAbcDatuyIqvp8VRVw1dC2JEkjMuprIsdU1QMA7f1Zrb4C2DU0bqbV9lefmac+ryQbk0wnmZ6dnT3gnZAkDRwsF9bnu55RHfV5VdXmqlpTVWumpub9mWBJUodRh8iD7VQU7f2hVp8BjhsatxK4/zHqK+epS5JGaNQhcj0wd4fVeuC6ofr57S6tU4GH2+muG4DTkyxvF9RPB25oy76V5NR2V9b5Q9uSJI3Ioj07K8mHgV8Djk4yw+Auq7cB1yTZANwHnNuGfxw4C9gJfBe4AKCqdie5BLi5jbu4quYu1v8+gzvAngL8R3tJkkZo0UKkql6/j0WnzTO2gAv3sZ0twJZ56tPAiw6kR0nSgTlYLqxLkpYgQ0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdRtLiCT5kyR3JrkjyYeTHJ7k+CQ3JdmR5CNJDmtjn9zmd7blq4a285ZWvyfJGePYF0maZCMPkSQrgDcBa6rqRcAhwHnA24HLqmo1sAfY0FbZAOypqucBl7VxJDmhrfdCYC3wviSHjHJfJGnSjet01jLgKUmWAU8FHgBeDVzblm8Fzm7T69o8bflpSdLqV1fV96vqK8BO4OQR9S9JYgwhUlX/C7wDuI9BeDwMbAe+UVV727AZYEWbXgHsauvubeOfOVyfZ52fkWRjkukk07Ozs0/sDknSBBvH6azlDI4ijgeeDTwNOHOeoTW3yj6W7av+6GLV5qpaU1VrpqamHn/TkqR5jeN01q8DX6mq2ar6IfAx4OXAke30FsBK4P42PQMcB9CWPwPYPVyfZx1J0giMI0TuA05N8tR2beM04C7gU8A5bcx64Lo2fX2bpy3/ZFVVq5/X7t46HlgNfHFE+yBJYnCBe6Sq6qYk1wJfAvYCtwCbgX8Hrk7y1la7oq1yBfDBJDsZHIGc17ZzZ5JrGATQXuDCqvrRSHdGkibcyEMEoKo2AZseUb6Xee6uqqrvAefuYzuXApc+4Q1KkhbEb6xLkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG5jCZEkRya5NsmXk9yd5GVJjkqyLcmO9r68jU2SdyfZmeS2JCcObWd9G78jyfpx7IskTbJxHYm8C/hEVb0AeAlwN3ARcGNVrQZubPMAZwKr22sjcDlAkqOATcApwMnAprngkSSNxshDJMkRwCuBKwCq6gdV9Q1gHbC1DdsKnN2m1wFX1cAXgCOTHAucAWyrqt1VtQfYBqwd4a5I0sRbUIgkuXEhtQV6LjALfCDJLUnen+RpwDFV9QBAe39WG78C2DW0/kyr7as+X/8bk0wnmZ6dne1sW5L0SPsNkSSHt9NGRydZ3q5bHJVkFfDszs9cBpwIXF5VLwW+w09PXc3bxjy12k/90cWqzVW1pqrWTE1NPd5+JUn78FhHIr8HbAde0N7nXtcB7+38zBlgpqpuavPXMgiVB9tpKtr7Q0PjjxtafyVw/37qkqQR2W+IVNW7qup44M+q6rlVdXx7vaSq/rHnA6vqa8CuJM9vpdOAu4Drgbk7rNYzCCpa/fx2l9apwMPtdNcNwOntCGk5cHqrSZJGZNlCBlXVe5K8HFg1vE5VXdX5uX8EfCjJYcC9wAUMAu2aJBuA+4Bz29iPA2cBO4HvtrFU1e4klwA3t3EXV9Xuzn4kSR0WFCJJPgj8MnAr8KNWLqArRKrqVmDNPItOm2dsARfuYztbgC09PUiSDtyCQoTBf/gntP/QJUkCFv49kTuAX1zMRiRJS89Cj0SOBu5K8kXg+3PFqnrNonQlSVoSFhoif7OYTUiSlqaF3p31mcVuRJK09Cz07qxv8dNvgx8GHAp8p6qOWKzGJEkHv4UeifzC8HySsxk8OVeSNMG6nuJbVf8CvPoJ7kWStMQs9HTWa4dmn8TgeyN+Z0SSJtxC7876raHpvcBXGfzOhyRpgi30msgFi92IJGnpWeiPUq1M8s9JHkryYJKPJlm52M1Jkg5uC72w/gEGj2R/NoNfD/zXVpMkTbCFhshUVX2gqva215WAPxEoSRNuoSHy9SRvTHJIe70R+L/FbEySdPBbaIj8LvA64GvAA8A5tB+HkiRNroXe4nsJsL6q9gAkOQp4B4NwkSRNqIUeibx4LkBg8NO0wEsXpyVJ0lKx0BB5UpLlczPtSGShRzGSpJ9TCw2CdwL/leRaBo87eR1w6aJ1JUlaEhb6jfWrkkwzeOhigNdW1V2L2pkk6aC34FNSLTQMDknST3Q9Cl6SJDBEJEkHwBCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSt7GFSPtxq1uS/FubPz7JTUl2JPlIksNa/cltfmdbvmpoG29p9XuSnDGePZGkyTXOI5E3A3cPzb8duKyqVgN7gA2tvgHYU1XPAy5r40hyAnAe8EJgLfC+JIeMqHdJEmMKkSQrgd8A3t/mw+Dhjte2IVuBs9v0ujZPW35aG78OuLqqvl9VXwF2AiePZg8kSTC+I5F/AP4C+HGbfybwjara2+ZngBVtegWwC6Atf7iN/0l9nnV+RpKNSaaTTM/Ozj6R+yFJE23kIZLkN4GHqmr7cHmeofUYy/a3zs8WqzZX1ZqqWjM1NfW4+pUk7ds4fp3wFcBrkpwFHA4cweDI5Mgky9rRxkrg/jZ+BjgOmEmyDHgGsHuoPmd4HUnSCIz8SKSq3lJVK6tqFYML45+sqjcAnwLOacPWA9e16evbPG35J6uqWv28dvfW8cBq4Isj2g1JEgfX76T/JXB1krcCtwBXtPoVwAeT7GRwBHIeQFXdmeQaBj+UtRe4sKp+NPq2JWlyjTVEqurTwKfb9L3Mc3dVVX0POHcf61+Kv/UuSWPjN9YlSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRCRJ3QwRSVI3Q0SS1M0QkSR1M0QkSd0MEUlSN0NEktTNEJEkdTNEJEndDBFJUjdDRJLUbeQhkuS4JJ9KcneSO5O8udWPSrItyY72vrzVk+TdSXYmuS3JiUPbWt/G70iyftT7IkmTbhxHInuBP62qXwFOBS5McgJwEXBjVa0GbmzzAGcCq9trI3A5DEIH2AScApwMbJoLHknSaIw8RKrqgar6Upv+FnA3sAJYB2xtw7YCZ7fpdcBVNfAF4MgkxwJnANuqandV7QG2AWtHuCuSNPHGek0kySrgpcBNwDFV9QAMggZ4Vhu2Atg1tNpMq+2rPt/nbEwynWR6dnb2idwFSZpoYwuRJE8HPgr8cVV9c39D56nVfuqPLlZtrqo1VbVmamrq8TcrSZrXWEIkyaEMAuRDVfWxVn6wnaaivT/U6jPAcUOrrwTu309dkjQi47g7K8AVwN1V9fdDi64H5u6wWg9cN1Q/v92ldSrwcDvddQNwepLl7YL66a0mSRqRZWP4zFcAvwPcnuTWVvsr4G3ANUk2APcB57ZlHwfOAnYC3wUuAKiq3UkuAW5u4y6uqt2j2QVJEowhRKrqc8x/PQPgtHnGF3DhPra1BdjyxHUnSXo8/Ma6JKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSuhkikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6maISJK6GSKSpG6GiCSpmyEiSepmiEiSui35EEmyNsk9SXYmuWjc/UjSJFnSIZLkEOC9wJnACcDrk5ww3q4kaXIs6RABTgZ2VtW9VfUD4Gpg3Zh7kqSJsWzcDRygFcCuofkZ4JRHDkqyEdjYZr+d5J4R9DYJjga+Pu4mDgZ5x/pxt6BH8+9zzqYc6Baes68FSz1E5vuXqUcVqjYDmxe/ncmSZLqq1oy7D2k+/n2OxlI/nTUDHDc0vxK4f0y9SNLEWeohcjOwOsnxSQ4DzgOuH3NPkjQxlvTprKram+QPgRuAQ4AtVXXnmNuaJJ4i1MHMv88RSNWjLiFIkrQgS/10liRpjAwRSVI3Q0RdfNyMDlZJtiR5KMkd4+5lEhgietx83IwOclcCa8fdxKQwRNTDx83ooFVVnwV2j7uPSWGIqMd8j5tZMaZeJI2RIaIeC3rcjKSff4aIevi4GUmAIaI+Pm5GEmCIqENV7QXmHjdzN3CNj5vRwSLJh4HPA89PMpNkw7h7+nnmY08kSd08EpEkdTNEJEndDBFJUjdDRJLUzRCRJHUzRKRFlOTbj7F81eN92mySK5Occ2CdSU8MQ0SS1M0QkUYgydOT3JjkS0luTzL81ONlSbYmuS3JtUme2tY5KclnkmxPckOSY8fUvrRPhog0Gt8DfruqTgReBbwzydyDLJ8PbK6qFwPfBP4gyaHAe4BzquokYAtw6Rj6lvZr2bgbkCZEgL9N8krgxwwenX9MW7arqv6zTf8T8CbgE8CLgG0taw4BHhhpx9ICGCLSaLwBmAJOqqofJvkqcHhb9shnDxWD0Lmzql42uhalx8/TWdJoPAN4qAXIq4DnDC37pSRzYfF64HPAPcDUXD3JoUleONKOpQUwRKTR+BCwJsk0g6OSLw8tuxtYn+Q24Cjg8vazw+cAb0/y38CtwMtH3LP0mHyKrySpm0cikqRuhogkqZshIknqZohIkroZIpKkboaIJKmbISJJ6vb/dCg23nZ1/ssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### we will try to visualize some distribution, so using countplot data is not imbalanced\n",
    "sns.countplot(df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import NLP specific data pre-processing libraries\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function for cleaning text like remove punctuations, digits and other than alphabet word\n",
    "def text_analyzer(messages):\n",
    "    porter = PorterStemmer()\n",
    "    clean_corpus = []\n",
    "    \n",
    "    for i in range(len(messages)):\n",
    "        \n",
    "        text = messages.iloc[i]\n",
    "        clean_text = re.sub('[^a-zA-Z]',' ',text)\n",
    "        \n",
    "        clean_text = clean_text.lower()\n",
    "        clean_text = clean_text.split()\n",
    "        \n",
    "        clean_text = [porter.stem(word) for word in clean_text if word not in stopwords.words('english')]\n",
    "        clean_text = ' '.join(clean_text)\n",
    "        \n",
    "        clean_corpus.append(clean_text)\n",
    "        \n",
    "    return clean_corpus\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20800\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_messages = text_analyzer(df_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hous dem aid even see comey letter jason chaffetz tweet',\n",
       " 'flynn hillari clinton big woman campu breitbart',\n",
       " 'truth might get fire',\n",
       " 'civilian kill singl us airstrik identifi',\n",
       " 'iranian woman jail fiction unpublish stori woman stone death adulteri',\n",
       " 'jacki mason hollywood would love trump bomb north korea lack tran bathroom exclus video breitbart',\n",
       " 'life life luxuri elton john favorit shark pictur stare long transcontinent flight',\n",
       " 'beno hamon win french socialist parti presidenti nomin new york time',\n",
       " 'excerpt draft script donald trump q ampa black church pastor new york time',\n",
       " 'back channel plan ukrain russia courtesi trump associ new york time']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean_messages[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we will work on Word embedding now\n",
    "#### declare variable vocabulary size\n",
    "voc_size = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence lenght in training corpus is 47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for msg in train_clean_messages:\n",
    "    msg_len = len(msg.split())\n",
    "    if msg_len > max_len:\n",
    "        max_len=msg_len\n",
    "\n",
    "print('Max Sentence lenght in training corpus is',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we will set sentence lenght to 40 as in testing corpus max sentence lenght is 27\n",
    "sent_len=40\n",
    "# we will set dimention as 40\n",
    "dim=40 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#### we will import some packages which are required for one hot representation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_corpus(vocsize,sentlen,message):\n",
    "    try:\n",
    "        one_hot_corpus = [one_hot(word,vocsize) for word in message]\n",
    "        padded_corpus = pad_sequences(one_hot_corpus,padding='pre',maxlen=sentlen)\n",
    "    except e:\n",
    "        print('exception is',e)\n",
    "    finally:\n",
    "        return padded_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_word_corpus=get_embedded_corpus(voc_size,sent_len,train_clean_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_word_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0, 2782, 4335, 3864,\n",
       "        1359,  485, 2665,  957, 1269, 3091,  895],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        2931, 1784,  952,  345, 1310, 1983, 4333]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_word_corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### now we will create neural network for text classification\n",
    "#### import required lib for the same\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models for hyper parameter tuning\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    for i,nodes in enumerate(layers):\n",
    "        if i==0:\n",
    "            model.add(Embedding(voc_size,dim,input_length=sent_len))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(LSTM(nodes))       \n",
    "            model.add(Dropout(0.2))\n",
    "        elif i==1:\n",
    "            model.add(LSTM(nodes))       \n",
    "            model.add(Dropout(0.2))\n",
    "        else:\n",
    "            model.add(Dense(nodes,activation='relu'))\n",
    "            model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedded corpus (20800, 40)\n",
      "Type of embedded corpus <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print('Shape of embedded corpus',cleaned_word_corpus.shape)\n",
    "print('Type of embedded corpus',type(cleaned_word_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cleaned_word_corpus\n",
    "y=df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label (20800,)\n",
      "Type of label <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print('Shape of label',y.shape)\n",
    "print('Type of label',type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1]\n",
      "Type of label <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "print(y[:5])\n",
    "print('Type of label',type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### we will now train and fit the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\slage\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\slage\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 16s 989us/step - loss: 0.4077 - accuracy: 0.8263\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 15s 902us/step - loss: 0.1586 - accuracy: 0.9386s -\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 10s 622us/step - loss: 0.1156 - accuracy: 0.9562\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 15s 885us/step - loss: 0.0901 - accuracy: 0.9659\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 15s 899us/step - loss: 0.0688 - accuracy: 0.9758\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 15s 879us/step - loss: 0.0541 - accuracy: 0.9825\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 15s 881us/step - loss: 0.0401 - accuracy: 0.9867\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 13s 809us/step - loss: 0.0283 - accuracy: 0.9910\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 13s 775us/step - loss: 0.0234 - accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 14s 830us/step - loss: 0.0211 - accuracy: 0.9936\n",
      "4160/4160 [==============================] - 1s 285us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.3814 - accuracy: 0.8361\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.1551 - accuracy: 0.9379\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 16s 985us/step - loss: 0.1101 - accuracy: 0.9589\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0877 - accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0659 - accuracy: 0.9779\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 16s 988us/step - loss: 0.0495 - accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0387 - accuracy: 0.9870\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 16s 983us/step - loss: 0.0290 - accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0208 - accuracy: 0.9934\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0194 - accuracy: 0.9944\n",
      "4160/4160 [==============================] - 1s 332us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.3688 - accuracy: 0.8320\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.1511 - accuracy: 0.9389\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 15s 929us/step - loss: 0.1053 - accuracy: 0.9611\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0787 - accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0582 - accuracy: 0.9819\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0456 - accuracy: 0.9856\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 16s 934us/step - loss: 0.0350 - accuracy: 0.9894\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 16s 941us/step - loss: 0.0254 - accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 16s 956us/step - loss: 0.0224 - accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 16s 934us/step - loss: 0.0216 - accuracy: 0.9935\n",
      "4160/4160 [==============================] - 1s 304us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 16s 973us/step - loss: 0.3727 - accuracy: 0.8317\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 15s 907us/step - loss: 0.1476 - accuracy: 0.9421\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 15s 916us/step - loss: 0.1071 - accuracy: 0.9592\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 15s 891us/step - loss: 0.0794 - accuracy: 0.9721\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 16s 932us/step - loss: 0.0600 - accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 15s 896us/step - loss: 0.0488 - accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 15s 890us/step - loss: 0.0352 - accuracy: 0.9879\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 15s 897us/step - loss: 0.0238 - accuracy: 0.9921\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0194 - accuracy: 0.9941\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 12s 737us/step - loss: 0.0300 - accuracy: 0.9899\n",
      "4160/4160 [==============================] - 1s 283us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 578s 35ms/step - loss: 0.3820 - accuracy: 0.8403\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 12s 751us/step - loss: 0.1488 - accuracy: 0.9424\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 10s 630us/step - loss: 0.1020 - accuracy: 0.9627\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 11s 649us/step - loss: 0.0741 - accuracy: 0.9745\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 13s 757us/step - loss: 0.0543 - accuracy: 0.9817\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 11s 677us/step - loss: 0.0407 - accuracy: 0.9862\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 11s 663us/step - loss: 0.0316 - accuracy: 0.9890\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 11s 660us/step - loss: 0.0200 - accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 14s 866us/step - loss: 0.0160 - accuracy: 0.9953\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 16s 952us/step - loss: 0.0154 - accuracy: 0.9957\n",
      "4160/4160 [==============================] - 2s 401us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 19s 1ms/step - loss: 0.5039 - accuracy: 0.7714\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 19s 1ms/step - loss: 0.1993 - accuracy: 0.9201\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 19s 1ms/step - loss: 0.1290 - accuracy: 0.9499\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0979 - accuracy: 0.9645\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0737 - accuracy: 0.9736\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0576 - accuracy: 0.9806\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0437 - accuracy: 0.9863\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0315 - accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.0249 - accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 17s 1ms/step - loss: 0.0197 - accuracy: 0.9944\n",
      "4160/4160 [==============================] - 2s 384us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.5557 - accuracy: 0.7305\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.2215 - accuracy: 0.9139\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.1390 - accuracy: 0.9469\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 18s 1ms/step - loss: 0.1075 - accuracy: 0.9603\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 23s 1ms/step - loss: 0.0854 - accuracy: 0.9702\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 35s 2ms/step - loss: 0.0664 - accuracy: 0.9770\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 36s 2ms/step - loss: 0.0505 - accuracy: 0.9835\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 36s 2ms/step - loss: 0.0393 - accuracy: 0.9871\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16640/16640 [==============================] - 37s 2ms/step - loss: 0.0329 - accuracy: 0.9898\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 38s 2ms/step - loss: 0.0232 - accuracy: 0.9927\n",
      "4160/4160 [==============================] - 5s 1ms/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 41s 2ms/step - loss: 0.5548 - accuracy: 0.7395\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.2321 - accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.1414 - accuracy: 0.9458\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.1038 - accuracy: 0.9626\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.0837 - accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.0631 - accuracy: 0.9809\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.0495 - accuracy: 0.9839\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.0388 - accuracy: 0.9879\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.0291 - accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 19s 1ms/step - loss: 0.0249 - accuracy: 0.9928\n",
      "4160/4160 [==============================] - 2s 401us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.5454 - accuracy: 0.7597\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.2142 - accuracy: 0.9159\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 21s 1ms/step - loss: 0.1390 - accuracy: 0.9463\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.1097 - accuracy: 0.9601\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.0858 - accuracy: 0.9694\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.0703 - accuracy: 0.9759\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 22s 1ms/step - loss: 0.0600 - accuracy: 0.9802\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 20s 1ms/step - loss: 0.0452 - accuracy: 0.9852\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 11s 646us/step - loss: 0.0352 - accuracy: 0.9889\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 11s 672us/step - loss: 0.0295 - accuracy: 0.9902\n",
      "4160/4160 [==============================] - 1s 344us/step\n",
      "Epoch 1/10\n",
      "16640/16640 [==============================] - 11s 670us/step - loss: 0.5014 - accuracy: 0.7573\n",
      "Epoch 2/10\n",
      "16640/16640 [==============================] - 11s 653us/step - loss: 0.1940 - accuracy: 0.9236\n",
      "Epoch 3/10\n",
      "16640/16640 [==============================] - 11s 651us/step - loss: 0.1223 - accuracy: 0.9541\n",
      "Epoch 4/10\n",
      "16640/16640 [==============================] - 11s 644us/step - loss: 0.0930 - accuracy: 0.9662\n",
      "Epoch 5/10\n",
      "16640/16640 [==============================] - 11s 642us/step - loss: 0.0674 - accuracy: 0.9777\n",
      "Epoch 6/10\n",
      "16640/16640 [==============================] - 11s 651us/step - loss: 0.0520 - accuracy: 0.9824\n",
      "Epoch 7/10\n",
      "16640/16640 [==============================] - 11s 662us/step - loss: 0.0388 - accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "16640/16640 [==============================] - 11s 642us/step - loss: 0.0313 - accuracy: 0.9889\n",
      "Epoch 9/10\n",
      "16640/16640 [==============================] - 10s 624us/step - loss: 0.0241 - accuracy: 0.9927\n",
      "Epoch 10/10\n",
      "16640/16640 [==============================] - 10s 628us/step - loss: 0.0194 - accuracy: 0.9942\n",
      "4160/4160 [==============================] - 1s 216us/step\n",
      "Epoch 1/10\n",
      "20800/20800 [==============================] - 14s 694us/step - loss: 0.3541 - accuracy: 0.8514\n",
      "Epoch 2/10\n",
      "20800/20800 [==============================] - 14s 664us/step - loss: 0.1492 - accuracy: 0.9405\n",
      "Epoch 3/10\n",
      "20800/20800 [==============================] - 14s 662us/step - loss: 0.1118 - accuracy: 0.9573\n",
      "Epoch 4/10\n",
      "20800/20800 [==============================] - 15s 734us/step - loss: 0.0852 - accuracy: 0.9690\n",
      "Epoch 5/10\n",
      "20800/20800 [==============================] - 17s 821us/step - loss: 0.0662 - accuracy: 0.9766\n",
      "Epoch 6/10\n",
      "20800/20800 [==============================] - 16s 758us/step - loss: 0.0509 - accuracy: 0.9835\n",
      "Epoch 7/10\n",
      "20800/20800 [==============================] - 15s 730us/step - loss: 0.0410 - accuracy: 0.9861\n",
      "Epoch 8/10\n",
      "20800/20800 [==============================] - 16s 757us/step - loss: 0.0314 - accuracy: 0.9899\n",
      "Epoch 9/10\n",
      "20800/20800 [==============================] - 15s 724us/step - loss: 0.0320 - accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "20800/20800 [==============================] - 14s 671us/step - loss: 0.0209 - accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "layers = [(100,),(50,50),(50,100,100,50)]\n",
    "\n",
    "param_grid = dict(layers=layers,batch_size=[128,256],epochs=[10])\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid,cv=5)\n",
    "\n",
    "grid_result = grid.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### we will check classification report and confusion matrix for calculating accuracy\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = grid_result.best_params_\n",
    "\n",
    "# predict output\n",
    "y_pred = grid_result.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3441    8]\n",
      " [  14 3401]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3449\n",
      "           1       1.00      1.00      1.00      3415\n",
      "\n",
      "    accuracy                           1.00      6864\n",
      "   macro avg       1.00      1.00      1.00      6864\n",
      "weighted avg       1.00      1.00      1.00      6864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128, 'epochs': 10, 'layers': (100,)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(i) for i in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  label\n",
       "0  20800      0\n",
       "1  20801      1\n",
       "2  20802      0\n",
       "3  20803      1\n",
       "4  20804      1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### now we will try to fit this model on test data\n",
    "submission = pd.read_csv('submit.csv')\n",
    "submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of submission df 5200\n",
      "length of test df (null already removed) 5200\n"
     ]
    }
   ],
   "source": [
    "print('length of submission df',len(submission))\n",
    "print('length of test df (null already removed)',len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(df_test,submission,how='inner')[['title','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  label\n",
       "0  Specter of Trump Loosens Tongues, if Not Purse...      0\n",
       "1  Russian warships ready to strike terrorists ne...      1\n",
       "2  #NoDAPL: Native American Leaders Vow to Stay A...      0\n",
       "3  Tim Tebow Will Attempt Another Comeback, This ...      1\n",
       "4                    Keiser Report: Meme Wars (E995)      1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1aea5a859c8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_messages = text_analyzer(test_df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sentence lenght in corpus is testing data 29\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for msg in test_clean_messages:\n",
    "    msg_len = len(msg.split())\n",
    "    if msg_len > max_len:\n",
    "        max_len=msg_len\n",
    "\n",
    "print('Max Sentence lenght in corpus is testing data',max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can set sentence lenght as set in training\n",
    "cleaned_test_word_corpus=get_embedded_corpus(voc_size,sent_len,test_clean_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0, 1613, 2159,  160, 1774,\n",
       "         912, 3117,  526,  678, 1621, 1726, 2651],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "        3069, 1215, 3598, 4905,  242, 1920, 4275],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0, 1111, 3487, 3685,\n",
       "        1090, 2212,  121, 4278, 3380,  729, 4822],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,  757, 4970,   15,\n",
       "        3820, 2550, 2651, 3706, 1621, 1726, 2651],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0, 3054, 4813, 1020, 2698, 1277]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_test_word_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = grid_result.predict(cleaned_test_word_corpus)\n",
    "#y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5200"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test_y=list(test_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = [int(i) for i in y_pred_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 1]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_test_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.66      0.62      2339\n",
      "           1       0.69      0.62      0.66      2861\n",
      "\n",
      "    accuracy                           0.64      5200\n",
      "   macro avg       0.64      0.64      0.64      5200\n",
      "weighted avg       0.65      0.64      0.64      5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_test_y,y_pred_test))\n",
    "#print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1550  789]\n",
      " [1080 1781]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(real_test_y,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = df_test[['id']]\n",
    "my_submission['label'] = y_pred_test\n",
    "my_submission.to_csv('my_submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will dump model now\n",
    "import pickle\n",
    "file_ip=open('ModelFakeClassifier.pkl','wb')\n",
    "pickle.dump(grid_result,file_ip)\n",
    "\n",
    "file_ip.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
